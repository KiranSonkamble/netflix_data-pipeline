{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f1d3db-3637-41b1-8cde-15945cea93ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## to Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4043789d-dfd8-4514-b3ea-b68808370f5f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "libraries"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, when, count\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192c1ad2-a4fc-4bc6-8827-3969b95a7b38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "external locations"
    }
   },
   "outputs": [],
   "source": [
    "silver_path_netflix_cast = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_cast\"\n",
    "silver_path_netflix_category = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_category\"\n",
    "silver_path_netflix_countries = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_countries\"\n",
    "silver_path_netflix_directors = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_directors\"\n",
    "silver_path_netflix_titles = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_titles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "606a6f56-4532-477d-b66e-ea04fade8dc4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Batch read netflix_cast  table"
    }
   },
   "outputs": [],
   "source": [
    "# Paths for one table (Netflix cast)\n",
    "silver_path_netflix_cast = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_cast\"\n",
    "gold_path_netflix_cast = \"abfss://gold@storageforproject.dfs.core.windows.net/netflix_cast\"\n",
    "\n",
    "\n",
    "@dlt.table(comment=\"Read Delta files from silver container (batch)\")\n",
    "def netflix_cast():\n",
    "\n",
    "    return (spark.read.format(\"delta\")\n",
    "            .load(silver_path_netflix_cast)\n",
    "            )\n",
    "    \n",
    "@dlt.table(comment=\"transform the data and save to delta\",location=gold_path_netflix_cast)\n",
    "@dlt.expect(\"valid_show_id\",\"show_id IS NOT NULL\")\n",
    "\n",
    "def Netflix_cast():\n",
    "    return(\n",
    "        dlt.read(\"netflix_cast\").dropDuplicates()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95b92b4c-005e-4d69-bb82-f04068daf7fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read table netflix_category"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@dlt.table(comment=\"Read Delta files from silver container (batch)\")\n",
    "\n",
    "def netflix_category():\n",
    "    df = spark.read.format(\"delta\").load(silver_path_netflix_category)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2706690-4659-42ba-950c-966a1dc13b08",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read netflix_countries"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(comment=\"Read netflix_countries files from silver container (batch)\")\n",
    "\n",
    "def netflix_countries():\n",
    "    return (spark.read.format(\"delta\").load(silver_path_netflix_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0e8aaf3-dc00-40e9-92dd-6957dfe67e0c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read netflix_directors"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(comment=\"Read netflix_directors files from silver container (batch)\")\n",
    "\n",
    "def netflix_directors():\n",
    "    return(spark.read.format(\"delta\").load(silver_path_netflix_directors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97eda8af-d41a-485c-8cab-c0d1e96ae50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If the Silver data is static and only updated occasionally, `batch` reading makes sense. Batch reads are straightforward and efficient for one-time processing. However, if the Silver layer is continuously being updated with new data (like in a real-time pipeline), `streaming` would be better to process those updates incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23acac12-2a37-4bf7-a406-22c9690d48a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Streaming netflix_titles table"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(comment=\"read netflix_titles files from silver container(stream)\")\n",
    "\n",
    "def stream_netflix_titles():\n",
    "      return (\n",
    "            spark.readStream.format(\"delta\").load(silver_path_netflix_titles)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13c4a41c-f146-4421-830d-c0db65b499fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "validate data"
    }
   },
   "outputs": [],
   "source": [
    "# DLT expectations are for validating data, not transforming it.\n",
    "# EXPECTATION RULES (DATA QUALITY CHECKS)\n",
    "expectation_rules = {\n",
    "    \"valid_show_id\": \"show_id IS NOT NULL\",          # Drop rows with null show_id\n",
    "    \"valid_release_year\": \"release_year IS NOT NULL\",# Drop rows with null release_year\n",
    "    \"valid_date_added\": \"date_added IS NOT NULL\"     # Drop rows with null date_added\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9d14c22-a003-4600-91a5-14e3d0bf3144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(comment=\"cleaned netflix_titles table \")\n",
    "@dlt.expect_all_or_drop(expectation_rules)\n",
    "\n",
    "def clean_netflix_titles():\n",
    "    df = dlt.read(\"stream_netflix_titles\").dropDuplicates()\\\n",
    "        .withColumn(\"description\", when(col(\"description\").isNull(), \"No description\").otherwise(col(\"description\")))\\\n",
    "        .withColumn(\"release_year\",col(\"release_year\").cast(IntegerType()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe9d8447-3531-4d38-bad3-1b08ec053206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "when reading from a Delta table that's part of the same pipeline, using dlt.read is better for lineage and dependency management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "607fd124-a1a5-44bf-9b46-57977c9d5de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(comment=\"create a view\")\n",
    "@dlt.expect(\"valid_release_year\",\"release_year IS NOT NULL\")\n",
    "\n",
    "def netflix_title_view():\n",
    "    return(\n",
    "        dlt.read(\"LIVE.clean_netflix_titles\")\n",
    "        .withColumn(\"new_flag\",when(col(\"type\")==\"Movie\",1).otherwise(0))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b7dc191-f001-49cd-b103-4ff35ecefdb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(comment=\"create a view\")\n",
    "@dlt.expect(\"valid_release_year\",\"release_year IS NOT NULL\")\n",
    "\n",
    "def netflix_title_view_1():\n",
    "    return(\n",
    "        dlt.read(\"clean_netflix_titles\")\n",
    "        .withColumn(\"new_flag\",when(col(\"type\")==\"Movie\",1).otherwise(0))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9f832a3-d431-4e29-b3ee-1c91589b27fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Similarly, define functions for the other tables.\n",
    "# Table 2: Netflix Titles\n",
    "silver_path_netflix_titles = \"abfss://silver@storageforproject.dfs.core.windows.net/netflix_titles\"\n",
    "gold_path_netflix_titles = \"abfss://gold@storageforproject.dfs.core.windows.net/netflix_titles\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e660225-d948-41cf-9a6f-03001d701e95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7_final file",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
